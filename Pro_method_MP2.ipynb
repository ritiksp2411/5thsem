{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pro-method-MP2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBjbS0MpWocONGgUzKF+8a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritiksp2411/5thsem/blob/master/Pro_method_MP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9jRjQt2xNYd",
        "outputId": "21bd30a8-832b-42a0-a1cb-e13f91ff978b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oRZPkuSxpnZ"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "\n",
        "def loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    return data.DataLoader(\n",
        "        datasets.ImageFolder(path,\n",
        "                             transforms.Compose([\n",
        "                                 transforms.Scale(256),\n",
        "                                 transforms.RandomSizedCrop(224),\n",
        "                                 transforms.RandomHorizontalFlip(),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 normalize,\n",
        "                             ])),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory)\n",
        "\n",
        "def test_loader(path, batch_size=32, num_workers=4, pin_memory=True):\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    return data.DataLoader(\n",
        "        datasets.ImageFolder(path,\n",
        "                             transforms.Compose([\n",
        "                                 transforms.Scale(256),\n",
        "                                 transforms.CenterCrop(224),\n",
        "                                 transforms.ToTensor(),\n",
        "                                 normalize,\n",
        "                             ])),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=pin_memory)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGDQ9gKfxkYv",
        "outputId": "e3a8bf93-d190-463b-81dd-39b82f871a4f"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import time\n",
        " \n",
        "def replace_layers(model, i, indexes, layers):\n",
        "    if i in indexes:\n",
        "        return layers[indexes.index(i)]\n",
        "    return model[i]\n",
        "\n",
        "def prune_vgg16_conv_layer(model, layer_index, filter_index):\n",
        "    _, conv = list(model.features._modules.items())[layer_index]\n",
        "    next_conv = None\n",
        "    offset = 1\n",
        "\n",
        "    while layer_index + offset <  len(model.features._modules.items()):\n",
        "        res =  list(model.features._modules.items())[layer_index+offset]\n",
        "        if isinstance(res[1], torch.nn.modules.conv.Conv2d):\n",
        "            next_name, next_conv = res\n",
        "            break\n",
        "        offset = offset + 1\n",
        "    \n",
        "    new_conv = \\\n",
        "        torch.nn.Conv2d(in_channels = conv.in_channels, \\\n",
        "            out_channels = conv.out_channels - 1,\n",
        "            kernel_size = conv.kernel_size, \\\n",
        "            stride = conv.stride,\n",
        "            padding = conv.padding,\n",
        "            dilation = conv.dilation,\n",
        "            groups = conv.groups,\n",
        "            bias = (conv.bias is not None))\n",
        "\n",
        "    old_weights = conv.weight.data.cpu().numpy()\n",
        "    new_weights = new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "    new_weights[: filter_index, :, :, :] = old_weights[: filter_index, :, :, :]\n",
        "    new_weights[filter_index : , :, :, :] = old_weights[filter_index + 1 :, :, :, :]\n",
        "    new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "    bias_numpy = conv.bias.data.cpu().numpy()\n",
        "\n",
        "    bias = np.zeros(shape = (bias_numpy.shape[0] - 1), dtype = np.float32)\n",
        "    bias[:filter_index] = bias_numpy[:filter_index]\n",
        "    bias[filter_index : ] = bias_numpy[filter_index + 1 :]\n",
        "    new_conv.bias.data = torch.from_numpy(bias)\n",
        "\n",
        "    if not next_conv is None:\n",
        "        next_new_conv = \\\n",
        "            torch.nn.Conv2d(in_channels = next_conv.in_channels - 1,\\\n",
        "                out_channels =  next_conv.out_channels, \\\n",
        "                kernel_size = next_conv.kernel_size, \\\n",
        "                stride = next_conv.stride,\n",
        "                padding = next_conv.padding,\n",
        "                dilation = next_conv.dilation,\n",
        "                groups = next_conv.groups,\n",
        "                bias = (next_conv.bias is not None))\n",
        "\n",
        "        old_weights = next_conv.weight.data.cpu().numpy()\n",
        "        new_weights = next_new_conv.weight.data.cpu().numpy()\n",
        "\n",
        "        new_weights[:, : filter_index, :, :] = old_weights[:, : filter_index, :, :]\n",
        "        new_weights[:, filter_index : , :, :] = old_weights[:, filter_index + 1 :, :, :]\n",
        "        next_new_conv.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "        next_new_conv.bias.data = next_conv.bias.data\n",
        "\n",
        "    if not next_conv is None:\n",
        "        features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index, layer_index+offset], \\\n",
        "                    [new_conv, next_new_conv]) for i, _ in enumerate(model.features)))\n",
        "        del model.features\n",
        "        del conv\n",
        "\n",
        "        model.features = features\n",
        "\n",
        "    else:\n",
        "        #Prunning the last conv layer. This affects the first linear layer of the classifier.\n",
        "        model.features = torch.nn.Sequential(\n",
        "                *(replace_layers(model.features, i, [layer_index], \\\n",
        "                    [new_conv]) for i, _ in enumerate(model.features)))\n",
        "        layer_index = 0\n",
        "        old_linear_layer = None\n",
        "        for _, module in model.classifier._modules.items():\n",
        "            if isinstance(module, torch.nn.Linear):\n",
        "                old_linear_layer = module\n",
        "                break\n",
        "            layer_index = layer_index  + 1\n",
        "\n",
        "        if old_linear_layer is None:\n",
        "            raise BaseException(\"No linear laye found in classifier\")\n",
        "        params_per_input_channel = old_linear_layer.in_features // conv.out_channels\n",
        "\n",
        "        new_linear_layer = \\\n",
        "            torch.nn.Linear(old_linear_layer.in_features - params_per_input_channel, \n",
        "                old_linear_layer.out_features)\n",
        "        \n",
        "        old_weights = old_linear_layer.weight.data.cpu().numpy()\n",
        "        new_weights = new_linear_layer.weight.data.cpu().numpy()        \n",
        "\n",
        "        new_weights[:, : filter_index * params_per_input_channel] = \\\n",
        "            old_weights[:, : filter_index * params_per_input_channel]\n",
        "        new_weights[:, filter_index * params_per_input_channel :] = \\\n",
        "            old_weights[:, (filter_index + 1) * params_per_input_channel :]\n",
        "        \n",
        "        new_linear_layer.bias.data = old_linear_layer.bias.data\n",
        "\n",
        "        new_linear_layer.weight.data = torch.from_numpy(new_weights)\n",
        "\n",
        "        classifier = torch.nn.Sequential(\n",
        "            *(replace_layers(model.classifier, i, [layer_index], \\\n",
        "                [new_linear_layer]) for i, _ in enumerate(model.classifier)))\n",
        "\n",
        "        del model.classifier\n",
        "        del next_conv\n",
        "        del conv\n",
        "        model.classifier = classifier\n",
        "\n",
        "    return model\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.train()\n",
        "\n",
        "t0 = time.time()\n",
        "model = prune_vgg16_conv_layer(model, 28, 10)\n",
        "print(\"The prunning took\", time.time() - t0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The prunning took 0.8621408939361572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZcPUxzPyVso"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "import cv2\n",
        "import sys\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "from operator import itemgetter\n",
        "from heapq import nsmallest\n",
        "import time\n",
        "\n",
        "class ModifiedVGG16Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedVGG16Model, self).__init__()\n",
        "\n",
        "        model = models.vgg16(pretrained=True)\n",
        "        self.features = model.features\n",
        "\n",
        "        for param in self.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(25088, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class FilterPrunner:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        self.filter_ranks = {}\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.activations = []\n",
        "        self.gradients = []\n",
        "        self.grad_index = 0\n",
        "        self.activation_to_layer = {}\n",
        "\n",
        "        activation_index = 0\n",
        "        for layer, (name, module) in enumerate(self.model.features._modules.items()):\n",
        "            x = module(x)\n",
        "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "                x.register_hook(self.compute_rank)\n",
        "                self.activations.append(x)\n",
        "                self.activation_to_layer[activation_index] = layer\n",
        "                activation_index += 1\n",
        "\n",
        "        return self.model.classifier(x.view(x.size(0), -1))\n",
        "\n",
        "    def compute_rank(self, grad):\n",
        "        activation_index = len(self.activations) - self.grad_index - 1\n",
        "        activation = self.activations[activation_index]\n",
        "\n",
        "        taylor = activation * grad\n",
        "        # Get the average value for every filter, \n",
        "        # accross all the other dimensions\n",
        "        taylor = taylor.mean(dim=(0, 2, 3)).data\n",
        "\n",
        "\n",
        "        if activation_index not in self.filter_ranks:\n",
        "            self.filter_ranks[activation_index] = \\\n",
        "                torch.FloatTensor(activation.size(1)).zero_()\n",
        "\n",
        "        self.filter_ranks[activation_index] += taylor\n",
        "        self.grad_index += 1\n",
        "\n",
        "    def lowest_ranking_filters(self, num):\n",
        "        data = []\n",
        "        for i in sorted(self.filter_ranks.keys()):\n",
        "            for j in range(self.filter_ranks[i].size(0)):\n",
        "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
        "\n",
        "        return nsmallest(num, data, itemgetter(2))\n",
        "\n",
        "    def normalize_ranks_per_layer(self):\n",
        "        for i in self.filter_ranks:\n",
        "            v = torch.abs(self.filter_ranks[i])\n",
        "            v = v / np.sqrt(torch.sum(v * v))\n",
        "            self.filter_ranks[i] = v.cpu()\n",
        "\n",
        "    def get_prunning_plan(self, num_filters_to_prune):\n",
        "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
        "\n",
        "        # After each of the k filters are prunned,\n",
        "        # the filter index of the next filters change since the model is smaller.\n",
        "        filters_to_prune_per_layer = {}\n",
        "        for (l, f, _) in filters_to_prune:\n",
        "            if l not in filters_to_prune_per_layer:\n",
        "                filters_to_prune_per_layer[l] = []\n",
        "            filters_to_prune_per_layer[l].append(f)\n",
        "\n",
        "        for l in filters_to_prune_per_layer:\n",
        "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
        "            for i in range(len(filters_to_prune_per_layer[l])):\n",
        "                filters_to_prune_per_layer[l][i] = filters_to_prune_per_layer[l][i] - i\n",
        "\n",
        "        filters_to_prune = []\n",
        "        for l in filters_to_prune_per_layer:\n",
        "            for i in filters_to_prune_per_layer[l]:\n",
        "                filters_to_prune.append((l, i))\n",
        "\n",
        "        return filters_to_prune             \n",
        "\n",
        "class PrunningFineTuner_VGG16:\n",
        "    def __init__(self, train_path, test_path, model):\n",
        "        self.train_data_loader = loader(train_path)\n",
        "        self.test_data_loader = test_loader(test_path)\n",
        "\n",
        "        self.model = model\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.prunner = FilterPrunner(self.model) \n",
        "        self.model.train()\n",
        "\n",
        "    def test(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (batch, label) in enumerate(self.test_data_loader):\n",
        "            output = model(Variable(batch))\n",
        "            pred = output.data.max(1)[1]\n",
        "            correct += pred.cpu().eq(label).sum()\n",
        "            total += label.size(0)\n",
        "        \n",
        "        print(\"Accuracy :\", float(correct) / total)\n",
        "        \n",
        "        self.model.train()\n",
        "\n",
        "    def train(self, optimizer = None, epoches=10):\n",
        "        if optimizer is None:\n",
        "            optimizer = optim.SGD(model.classifier.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "        for i in range(epoches):\n",
        "            print(\"Epoch: \", i)\n",
        "            self.train_epoch(optimizer)\n",
        "            self.test()\n",
        "        print(\"Finished fine tuning.\")\n",
        "        \n",
        "\n",
        "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
        "\n",
        "        self.model.zero_grad()\n",
        "        input = Variable(batch)\n",
        "\n",
        "        if rank_filters:\n",
        "            output = self.prunner.forward(input)\n",
        "            self.criterion(output, Variable(label)).backward()\n",
        "        else:\n",
        "            self.criterion(self.model(input), Variable(label)).backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
        "        for i, (batch, label) in enumerate(self.train_data_loader):\n",
        "            self.train_batch(optimizer, batch, label, rank_filters)\n",
        "\n",
        "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
        "        self.prunner.reset()\n",
        "        self.train_epoch(rank_filters = True)\n",
        "        self.prunner.normalize_ranks_per_layer()\n",
        "        return self.prunner.get_prunning_plan(num_filters_to_prune)\n",
        "        \n",
        "    def total_num_filters(self):\n",
        "        filters = 0\n",
        "        for name, module in self.model.features._modules.items():\n",
        "            if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "                filters = filters + module.out_channels\n",
        "        return filters\n",
        "\n",
        "    def prune(self):\n",
        "        #Get the accuracy before prunning\n",
        "        self.test()\n",
        "        self.model.train()\n",
        "\n",
        "        #Make sure all the layers are trainable\n",
        "        for param in self.model.features.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        number_of_filters = self.total_num_filters()\n",
        "        num_filters_to_prune_per_iteration = 512\n",
        "        iterations = int(float(number_of_filters) / num_filters_to_prune_per_iteration)\n",
        "\n",
        "        iterations = int(iterations * 2.0 / 3)\n",
        "\n",
        "        print(\"Number of prunning iterations to reduce 67% filters\", iterations)\n",
        "\n",
        "        for _ in range(iterations):\n",
        "            print(\"Ranking filters.. \")\n",
        "            prune_targets = self.get_candidates_to_prune(num_filters_to_prune_per_iteration)\n",
        "            layers_prunned = {}Fine tuning to recover from prunning iteration.\n",
        "            for layer_index, filter_index in prune_targets:\n",
        "                if layer_index not in layers_prunned:\n",
        "                    layers_prunned[layer_index] = 0\n",
        "                layers_prunned[layer_index] = layers_prunned[layer_index] + 1 \n",
        "\n",
        "            print(\"Layers that will be prunned\", layers_prunned)\n",
        "            print(\"Prunning filters.. \")\n",
        "            model = self.model.cpu()\n",
        "            for layer_index, filter_index in prune_targets:\n",
        "                model = prune_vgg16_conv_layer(model, layer_index, filter_index)\n",
        "\n",
        "            self.model = model\n",
        "\n",
        "            message = str(100*float(self.total_num_filters()) / number_of_filters) + \"%\"\n",
        "            print(\"Filters prunned\", str(message))\n",
        "            self.test()\n",
        "            print(\"Fine tuning to recover from prunning iteration.\")\n",
        "            optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "            self.train(optimizer, epoches = 10)\n",
        "\n",
        "\n",
        "        print(\"Finished. Going to fine tune the model a bit more\")\n",
        "        self.train(optimizer, epoches=15)\n",
        "        torch.save(model.state_dict(), \"model_prunned\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL2Ogb-Hz2og"
      },
      "source": [
        "train = True\n",
        "prune = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz-v9uom1U4F"
      },
      "source": [
        "train_path = '/content/drive/My Drive/train/'\n",
        "test_path ='/content/drive/My Drive/test/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IATVglVf0ndO",
        "outputId": "028d207f-5734-4fbe-86c9-96bfcc4f2894"
      },
      "source": [
        "model = ModifiedVGG16Model()\n",
        "\n",
        "fine_tuner = PrunningFineTuner_VGG16(train_path, test_path, model)\n",
        "\n",
        "fine_tuner.train(epoches=5)\n",
        "torch.save(model, \"model\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:310: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:917: UserWarning: The use of the transforms.RandomSizedCrop transform is deprecated, please use transforms.RandomResizedCrop instead.\n",
            "  warnings.warn(\"The use of the transforms.RandomSizedCrop transform is deprecated, \" +\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.7\n",
            "Epoch:  1\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  2\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  3\n",
            "Accuracy : 0.48333333333333334\n",
            "Epoch:  4\n",
            "Accuracy : 0.5166666666666667\n",
            "Finished fine tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "racCum8_Wn_V",
        "outputId": "61c690fe-3806-4927-ae2f-1bd31537ca37"
      },
      "source": [
        "model = torch.load(\"model\", map_location=lambda storage, loc: storage)\n",
        "fine_tuner.prune()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.3333333333333333\n",
            "Number of prunning iterations to reduce 67% filters 5\n",
            "Ranking filters.. \n",
            "Layers that will be prunned {26: 76, 28: 75, 19: 73, 21: 58, 10: 20, 17: 59, 12: 25, 24: 84, 2: 5, 0: 6, 7: 11, 14: 16, 5: 4}\n",
            "Prunning filters.. \n",
            "Filters prunned 87.87878787878788%\n",
            "Accuracy : 0.43333333333333335\n",
            "Fine tuning to recover from prunning iteration.\n",
            "Epoch:  0\n",
            "Accuracy : 0.35\n",
            "Epoch:  1\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  2\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  3\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  4\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  5\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  6\n",
            "Accuracy : 0.4\n",
            "Epoch:  7\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  8\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  9\n",
            "Accuracy : 0.31666666666666665\n",
            "Finished fine tuning.\n",
            "Ranking filters.. \n",
            "Layers that will be prunned {17: 64, 28: 121, 26: 86, 2: 3, 5: 8, 24: 64, 12: 14, 19: 57, 14: 14, 21: 61, 10: 13, 7: 5, 0: 2}\n",
            "Prunning filters.. \n",
            "Filters prunned 75.75757575757575%\n",
            "Accuracy : 0.4666666666666667\n",
            "Fine tuning to recover from prunning iteration.\n",
            "Epoch:  0\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  1\n",
            "Accuracy : 0.4666666666666667\n",
            "Epoch:  2\n",
            "Accuracy : 0.36666666666666664\n",
            "Epoch:  3\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  4\n",
            "Accuracy : 0.4666666666666667\n",
            "Epoch:  5\n",
            "Accuracy : 0.3333333333333333\n",
            "Epoch:  6\n",
            "Accuracy : 0.45\n",
            "Epoch:  7\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  8\n",
            "Accuracy : 0.3333333333333333\n",
            "Epoch:  9\n",
            "Accuracy : 0.43333333333333335\n",
            "Finished fine tuning.\n",
            "Ranking filters.. \n",
            "Layers that will be prunned {21: 66, 26: 88, 12: 18, 24: 73, 17: 42, 28: 104, 10: 17, 19: 66, 14: 26, 0: 3, 5: 4, 7: 2, 2: 3}\n",
            "Prunning filters.. \n",
            "Filters prunned 63.63636363636363%\n",
            "Accuracy : 0.4666666666666667\n",
            "Fine tuning to recover from prunning iteration.\n",
            "Epoch:  0\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  1\n",
            "Accuracy : 0.35\n",
            "Epoch:  2\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  3\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  4\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  5\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  6\n",
            "Accuracy : 0.48333333333333334\n",
            "Epoch:  7\n",
            "Accuracy : 0.35\n",
            "Epoch:  8\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  9\n",
            "Accuracy : 0.4166666666666667\n",
            "Finished fine tuning.\n",
            "Ranking filters.. \n",
            "Layers that will be prunned {26: 80, 19: 53, 28: 94, 10: 19, 24: 85, 21: 53, 5: 13, 12: 22, 0: 7, 14: 23, 17: 50, 7: 8, 2: 5}\n",
            "Prunning filters.. \n",
            "Filters prunned 51.515151515151516%\n",
            "Accuracy : 0.38333333333333336\n",
            "Fine tuning to recover from prunning iteration.\n",
            "Epoch:  0\n",
            "Accuracy : 0.4666666666666667\n",
            "Epoch:  1\n",
            "Accuracy : 0.4666666666666667\n",
            "Epoch:  2\n",
            "Accuracy : 0.35\n",
            "Epoch:  3\n",
            "Accuracy : 0.31666666666666665\n",
            "Epoch:  4\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  5\n",
            "Accuracy : 0.4666666666666667\n",
            "Epoch:  6\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  7\n",
            "Accuracy : 0.35\n",
            "Epoch:  8\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  9\n",
            "Accuracy : 0.4166666666666667\n",
            "Finished fine tuning.\n",
            "Ranking filters.. \n",
            "Layers that will be prunned {12: 35, 14: 38, 5: 12, 17: 82, 24: 50, 28: 30, 26: 52, 10: 29, 21: 85, 2: 12, 0: 9, 19: 63, 7: 15}\n",
            "Prunning filters.. \n",
            "Filters prunned 39.39393939393939%\n",
            "Accuracy : 0.4666666666666667\n",
            "Fine tuning to recover from prunning iteration.\n",
            "Epoch:  0\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  1\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  2\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  3\n",
            "Accuracy : 0.31666666666666665\n",
            "Epoch:  4\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  5\n",
            "Accuracy : 0.45\n",
            "Epoch:  6\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  7\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  8\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  9\n",
            "Accuracy : 0.4166666666666667\n",
            "Finished fine tuning.\n",
            "Finished. Going to fine tune the model a bit more\n",
            "Epoch:  0\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  1\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  2\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  3\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  4\n",
            "Accuracy : 0.4\n",
            "Epoch:  5\n",
            "Accuracy : 0.31666666666666665\n",
            "Epoch:  6\n",
            "Accuracy : 0.4\n",
            "Epoch:  7\n",
            "Accuracy : 0.3333333333333333\n",
            "Epoch:  8\n",
            "Accuracy : 0.31666666666666665\n",
            "Epoch:  9\n",
            "Accuracy : 0.43333333333333335\n",
            "Epoch:  10\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  11\n",
            "Accuracy : 0.35\n",
            "Epoch:  12\n",
            "Accuracy : 0.4166666666666667\n",
            "Epoch:  13\n",
            "Accuracy : 0.38333333333333336\n",
            "Epoch:  14\n",
            "Accuracy : 0.43333333333333335\n",
            "Finished fine tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZccOwQFbR7N"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}